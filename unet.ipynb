{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_2(inc,outc):\n",
    "    conv = nn.Sequential(\n",
    "        nn.Conv2d(inc,outc,kernel_size=3),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(outc,outc,kernel_size=3),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(original, new):\n",
    "    new_size = new.size()[2]\n",
    "    original_size = original.size()[2]\n",
    "    diff = original_size - new_size\n",
    "    diff = diff // 2\n",
    "    return original[:,:,diff:original_size-diff,diff:original_size-diff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class U_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(U_net,self).__init__()\n",
    "        self.maxpool2x2 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.conv1down = conv_2(1,64)\n",
    "        self.conv2down = conv_2(64,128)\n",
    "        self.conv3down = conv_2(128,256)\n",
    "        self.conv4down = conv_2(256,512)\n",
    "        self.conv5down = conv_2(512,1024)\n",
    "        \n",
    "        self.conv_Trans1 = nn.ConvTranspose2d(in_channels=1024,out_channels=512,kernel_size=2,stride=2)\n",
    "        self.conv_up1 = conv_2(1024,512)\n",
    "        self.conv_Trans2 = nn.ConvTranspose2d(in_channels=512,out_channels=256,kernel_size=2,stride=2)\n",
    "        self.conv_up2 = conv_2(512,256)\n",
    "        self.conv_Trans3 = nn.ConvTranspose2d(in_channels=256,out_channels=128,kernel_size=2,stride=2)\n",
    "        self.conv_up3 = conv_2(256,128)\n",
    "        self.conv_Trans4 = nn.ConvTranspose2d(in_channels=128,out_channels=64,kernel_size=2,stride=2)\n",
    "        self.conv_up4 = conv_2(128,64)\n",
    "\n",
    "        self.output = nn.Conv2d(64,2,kernel_size=1)\n",
    "    def forward(self,img):\n",
    "        #encode\n",
    "        # b c h w\n",
    "        e1 = self.conv1down(img)\n",
    "        e2 = self.maxpool2x2(e1)\n",
    "        print(e1.size())\n",
    "        e3 = self.conv2down(e2)\n",
    "        e4 = self.maxpool2x2(e3)\n",
    "        print(e3.size())\n",
    "        \n",
    "        e5 = self.conv3down(e4)\n",
    "        e6 = self.maxpool2x2(e5)\n",
    "        print(e5.size())\n",
    "        \n",
    "        e7 = self.conv4down(e6)\n",
    "        e8 = self.maxpool2x2(e7)\n",
    "        print(e7.size())\n",
    "    \n",
    "        e9 = self.conv5down(e8)\n",
    "        print(e9.size())\n",
    "\n",
    "        #decode\n",
    "        x = self.conv_Trans1(e9)\n",
    "        y =crop(e7,x)\n",
    "        x = self.conv_up1(torch.cat([x,y],1))\n",
    "\n",
    "        x = self.conv_Trans2(x)\n",
    "        y =crop(e5,x)\n",
    "        x = self.conv_up2(torch.cat([x,y],1))\n",
    "\n",
    "        x = self.conv_Trans3(x)\n",
    "        y =crop(e3,x)\n",
    "        x = self.conv_up3(torch.cat([x,y],1))\n",
    "\n",
    "        x = self.conv_Trans4(x)\n",
    "        y =crop(e1,x)\n",
    "        x = self.conv_up4(torch.cat([x,y],1))\n",
    "        print(x.size())\n",
    "        \n",
    "        y = self.output(x) \n",
    "        print(y.size())\n",
    "        return y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 568, 568])\n",
      "torch.Size([1, 128, 280, 280])\n",
      "torch.Size([1, 256, 136, 136])\n",
      "torch.Size([1, 512, 64, 64])\n",
      "torch.Size([1, 1024, 28, 28])\n",
      "torch.Size([1, 64, 388, 388])\n",
      "torch.Size([1, 2, 388, 388])\n",
      "tensor([[[[ 0.1126,  0.1124,  0.1087,  ...,  0.1092,  0.1077,  0.1113],\n",
      "          [ 0.1076,  0.1103,  0.1110,  ...,  0.1073,  0.1127,  0.1102],\n",
      "          [ 0.1156,  0.1064,  0.1093,  ...,  0.1148,  0.1146,  0.1050],\n",
      "          ...,\n",
      "          [ 0.1100,  0.1088,  0.1131,  ...,  0.1147,  0.1125,  0.1126],\n",
      "          [ 0.1063,  0.1117,  0.0994,  ...,  0.1057,  0.1088,  0.1093],\n",
      "          [ 0.1103,  0.1103,  0.1166,  ...,  0.1118,  0.1171,  0.1114]],\n",
      "\n",
      "         [[ 0.0006, -0.0011, -0.0045,  ..., -0.0039, -0.0062, -0.0061],\n",
      "          [-0.0040, -0.0042,  0.0014,  ..., -0.0035, -0.0040,  0.0004],\n",
      "          [ 0.0046, -0.0112, -0.0010,  ..., -0.0010,  0.0002, -0.0094],\n",
      "          ...,\n",
      "          [-0.0057, -0.0037,  0.0011,  ...,  0.0005, -0.0070, -0.0054],\n",
      "          [ 0.0007, -0.0019, -0.0099,  ..., -0.0048, -0.0014, -0.0070],\n",
      "          [-0.0008, -0.0012,  0.0010,  ..., -0.0016, -0.0007, -0.0083]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    img = torch.rand((1,1,572,572))\n",
    "    modl = U_net()\n",
    "    print(modl(img))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
